# RFMix-reader
`RFMix-reader` is a Python package for efficiently reading and processing output
files generated by [`RFMix`](https://github.com/slowkoni/rfmix), a widely used tool
for estimating local ancestry in admixed populations.  
It employs a **lazy loading approach** to minimize memory usage, and leverages **GPU acceleration**
for major speedups when available.

---

## Installation

`rfmix-reader` requires **Python 3.10+**. Install from PyPI:

```bash
pip install rfmix-reader
````

### Installation Options

* **Basic install** (CPU only):

  ```bash
  pip install rfmix-reader
  ```

* **With GPU acceleration** (`cupy`, `cudf`, `dask-cudf`):

  ```bash
  pip install rfmix-reader[gpu]
  ```

* **With documentation tools** (`sphinx`, `sphinx-rtd-theme`):

  ```bash
  pip install rfmix-reader[docs]
  ```

* **With testing tools** (`pytest`):

  ```bash
  pip install rfmix-reader[tests]
  ```

### GPU Notes

* `torch` is installed automatically.
* For CUDA builds, install a matching GPU-enabled wheel for your system following the [PyTorch guide](https://pytorch.org/get-started/locally/).
* RAPIDS (`cudf`, `cupy`) wheels are version- and CUDA-specific. See the [RAPIDS install guide](https://docs.rapids.ai/install).
* CPU-only installations will still run efficiently, just without GPU acceleration.

---

## Quickstart

```python
from rfmix_reader import read_rfmix

# Load RFMix outputs (two-population admixture example)
file_path = "examples/two_populations/out/"
loci_df, g_anc, local_array = read_rfmix(file_path)

print(loci_df.head())
print(g_anc.head())
print(local_array.shape)

# Optionally phase each chromosome chunk using reference data
# (requires a bgzipped, indexed VCF plus sample annotations)
# phased_loci, phased_g_anc, phased_admix = read_rfmix(
#     file_path,
#     phase=True,
#     phase_vcf_path="/path/to/reference.vcf.gz",
#     phase_sample_annot_path="/path/to/sample_annot.tsv",
# )
```

---

## Key Features

* **Lazy Loading**: Reads data on-the-fly, reducing memory footprint.
* **Efficient Access**: Query specific loci or regions of interest.
* **Seamless Integration**: Works smoothly with `pandas`, `dask`, and other analysis tools.
* **Loci Imputation**: Impute local ancestry loci to dense genotype variant sites.
* **GPU Acceleration**: Automatic CUDA acceleration via PyTorch/CuPy when available.

---

## Simulation Data

Test datasets for two- and three-population admixture are available on Synapse:
[Synapse Project syn61691659](https://www.synapse.org/Synapse:syn61691659).

---

## Usage

### Binary Conversion

RFMix does not generate binary files directly.
Use `create_binaries` to generate them (also available as a CLI):

```bash
create-binaries two_pops/out/
```

```python
from rfmix_reader import create_binaries

create_binaries("two_pops/out/", binary_dir="./binary_files")
```

### Preparing Reference Data for Phasing

Use `prepare-reference` to convert bgzipped, indexed reference VCF/BCF files
into per-chromosome VCF-Zarr stores that `phase=True` consumes during
phasing. The command writes one `<chrom>.zarr` directory per input file.

```
prepare-reference -h
```

```
usage: prepare-reference [-h] [--chunk-length CHUNK_LENGTH]
                         [--samples-chunk-size SAMPLES_CHUNK_SIZE]
                         [--worker-processes WORKER_PROCESSES]
                         [--verbose | --no-verbose] [--version]
                         output_dir vcf_paths [vcf_paths ...]

Convert one or more bgzipped reference VCF/BCF files into Zarr stores.

positional arguments:
  output_dir            Directory where the Zarr outputs will be written.
  vcf_paths             Paths to reference VCF/BCF files (bgzipped and
                        indexed).

options:
  -h, --help            show this help message and exit
  --chunk-length CHUNK_LENGTH
                        Genomic chunk size for the output Zarr stores
                        (default: 100000).
  --samples-chunk-size SAMPLES_CHUNK_SIZE
                        Chunk size for samples in the output Zarr stores
                        (default: library chosen).
  --worker-processes WORKER_PROCESSES
                        Number of worker processes to use for conversion
                        (default: 0, use library default).
  --verbose, --no-verbose
                        Print progress messages (default: enabled).
  --version             Show the version of the program and exit.
```

Example end-to-end preparation:

```bash
# Sample annotations: two columns (no header): sample_id<TAB>group
cat > sample_annotations.tsv <<'EOF'
NA19700	AFR
NA19701	AFR
NA20847	EUR
EOF

# Convert chromosome VCFs into a reference store directory
prepare-reference refs/ 1kg_chr20.vcf.gz 1kg_chr21.vcf.gz \
  --chunk-length 50000 --samples-chunk-size 512

# Use the reference store + annotations during phasing
read_rfmix(
    "two_pops/out/",
    phase=True,
    phase_ref_zarr_root="refs",
    phase_sample_annot_path="sample_annotations.tsv",
)
```

### Main Function

Once binaries are available, process RFMix results:

```python
from rfmix_reader import read_rfmix

loci, g_anc, admix = read_rfmix("two_pops/out/")
```

### Three Population Example

Binaries can also be generated on-the-fly within `read_rfmix` with
`generate_binary` set to `True`.

```python
loci, g_anc, admix = read_rfmix("examples/three_populations/out/",
                               binary_dir="./binary_files",
                               generate_binary=True)
```

### Loci Imputation

The imputation workflow now lives in ``rfmix_reader.processing.imputation`` and
is exported as ``interpolate_array``. It interpolates the local ancestry matrix
onto a denser variant grid and writes the result to ``<zarr_outdir>/local-ancestry.zarr``
as a Zarr array shaped ``(variants, samples, ancestries)``.

**Inputs**

* ``variant_loci_df``: a pandas DataFrame defining the variant grid. Provide at
  least ``chrom``/``pos`` and an ``i`` column that points to the source RFMix
  row index; rows with ``i`` set to ``NaN`` are treated as missing loci to
  interpolate. Sort the frame by genomic coordinate, and include ``pos`` if you
  plan to interpolate in base-pair space.
* ``admix``: the local ancestry Dask array returned by ``read_rfmix`` (shape
  ``(loci, samples, ancestries)``).
* ``zarr_outdir``: an output directory where the new ``local-ancestry.zarr``
  store will be created.

**Key options**

* ``interpolation``: ``"linear"`` (default), ``"nearest"``, ``"stepwise"``, or
  ``"hmm"``. HMM interpolation is experimental, requires haplotype-level inputs
  created with ``split_to_haplotypes``, and must be explicitly enabled with
  ``allow_hmm=True``.
* ``use_bp_positions``: set to ``True`` to interpolate along ``variant_loci_df['pos']``
  rather than treating loci as equally spaced indices.
* ``chunk_size``/``batch_size``: tune how many rows are materialized at a time
  when filling and interpolating the Zarr array.

**Workflow example**

```python
import pandas as pd
from pathlib import Path
from rfmix_reader import interpolate_array, read_rfmix

# Load RFMix loci and local ancestry
loci_df, _, admix = read_rfmix("two_pops/out/", binary_dir="./binary_files")

# Build the variant grid by merging genotype sites with the RFMix loci index
variants = pd.read_parquet("genotypes/variants.parquet")  # must include chrom/pos
variants = variants.drop_duplicates(subset=["chrom", "pos"]).sort_values("pos")
variant_loci_df = (
    variants.merge(loci_df.to_pandas(), on=["chrom", "pos"], how="outer", indicator=True)
            .loc[:, ["chrom", "pos", "i", "_merge"]]
)

z = interpolate_array(
    variant_loci_df,
    admix,
    zarr_outdir=Path("./imputed_local_ancestry"),
    interpolation="linear",
    use_bp_positions=True,
    chunk_size=50_000,
)
print(z)
```

The interpolator uses GPU acceleration transparently when ``cupy`` and a CUDA
PyTorch build are available; otherwise it falls back to NumPy. All methods other
than ``"hmm"`` operate on diploid-summed trajectories and preserve the original
ancestry dimension.

### Phasing workflow (`rfmix_reader.processing.phase`)

`rfmix_reader.processing.phase` implements gnomix-style tail-flip corrections for
local ancestry haplotypes. The workflow is orchestrated through the
`phase_admix_dask_with_index` pipeline (used internally by `read_rfmix`) and is
configurable via `PhasingConfig`.

#### What `read_rfmix` does when `phase=True`

* Validates required phasing inputs (reference Zarr root + sample annotations)
  and builds a default `PhasingConfig` if one is not provided.
* Loads unphased per-chromosome local ancestry (`fb.tsv`) along with the raw
  RFMix matrix needed to reconstruct haplotypes.
* Calls `phase_admix_dask_with_index` to rechunk by sample, reconstruct
  haplotype-level ancestry from the raw matrix, and apply tail-flip corrections
  against reference haplotypes from VCF-Zarr stores.
* Returns a phased `(loci_df, g_anc, phased_admix)` tuple where `phased_admix`
  is a Dask array of shape `(L, S, A)`.

#### Required reference inputs

* **VCF-Zarr reference** (`phase_ref_zarr_root` or deprecated `phase_vcf_path`):
  either a single `*.zarr` store or a directory containing per-chromosome
  stores (e.g., `1.zarr`, `chr1.zarr`).
* **Sample annotations** (`phase_sample_annot_path`): two-column file mapping
  `sample_id` to `group` (ancestry label). One representative sample per group
  is pulled to build reference haplotypes.
* **Group filtering (optional)** (`phase_groups`): restrict phasing to a subset
  of group labels. Defaults to the ancestry columns inferred from `rfmix.Q`.

#### Outputs and diagnostics

* `phased_admix`: phase-corrected ancestry counts (`int8`) aligned to the input
  loci; shape `(L, S, A)`.
* `PhasingConfig`: tune window size, heterozygous block length, mismatch
  tolerance, and verbosity for debugging per-sample/reference matches.
* Reference matching statistics (counts of matched/missing loci per chromosome)
  are logged from `phase.py` when mismatches exceed the configurable threshold.

#### Runnable examples

```python
from rfmix_reader import read_rfmix, PhasingConfig

# Basic phasing with default parameters
loci_df, g_anc, phased_admix = read_rfmix(
    "examples/two_populations/out/",
    phase=True,
    phase_ref_zarr_root="/refs/1kg_chr_zarr/",  # directory containing <chrom>.zarr
    phase_sample_annot_path="/refs/1kg_annotations.tsv",
)

# Custom phasing options and group filtering
config = PhasingConfig(window_size=100, min_block_len=10, max_mismatch_frac=0.3)
loci_df, g_anc, phased_admix = read_rfmix(
    "examples/three_populations/out/",
    phase=True,
    phase_ref_zarr_root="/refs/1kg_chr_zarr/",
    phase_sample_annot_path="/refs/1kg_annotations.tsv",
    phase_groups=["AFR", "EUR", "NAT"],
    phase_config=config,
    phase_hap_index_in_vcf=1,  # use the second haploid allele in the VCF-Zarr
)

# Direct access to the phasing primitives
from rfmix_reader.processing.phase import phase_admix_dask_with_index

# Start from unphased outputs (return_original=True) and phase manually
loci_df, g_anc, admix, X_raw = read_rfmix(
    "examples/two_populations/out/",
    return_original=True,
)

phased = phase_admix_dask_with_index(
    admix=admix,  # (L, S, A) Dask array of summed counts
    X_raw=X_raw,  # raw RFMix matrix for reconstructing hap0/hap1
    positions=loci_df.physical_position.to_numpy(),
    chrom=str(loci_df.chromosome.iloc[0]),
    ref_zarr_root="/refs/1kg_chr_zarr/",
    sample_annot_path="/refs/1kg_annotations.tsv",
    config=config,
    groups=["AFR", "EUR"],
)
```

### Reading Haptools simulations

Use `read_simu` to load BGZF-compressed VCF files created by
`haptools simgenotype --pop_field`:

```python
from rfmix_reader import read_simu

loci_df, g_anc, admix = read_simu("/path/to/simulations/")
```

Haptools does **not** include the chromosome length in the `##contig`
header lines, but `read_simu` requires that metadata to index each VCF.
Copy the `contigs.txt` file Haptools generates from the FASTA you used
for simulation and reheader every file with the appropriate contig entry
before calling `read_simu`. The following snippet shows one approach
using `bcftools` and `tabix`:

```bash
CONTIGS="../../three_populations/_m/contigs.txt"
VCFDIR="gt-files"
CHR="chr${SLURM_ARRAY_TASK_ID}"
OUT="${VCFDIR}/${CHR}.vcf.gz"
IN="${VCFDIR}/back/${CHR}.vcf.gz"

CONTIG_LINE=$(grep -w "ID=${CHR}" "$CONTIGS")
if [[ -z "$CONTIG_LINE" ]]; then
    echo "ERROR: No contig line found for ${CHR} in $CONTIGS"
    exit 1
fi

bcftools view -h "$IN" \
    | sed "s/^##contig=<ID=${CHR}>.*/${CONTIG_LINE}/" > header.${CHR}.tmp
bcftools reheader -h header.${CHR}.tmp -o "$OUT" "$IN"
tabix -p vcf "$OUT"
```

### Visualization

`read_rfmix`, `read_flare`, and `read_simu` all return the same
`(loci_df, g_anc, admix)` tuple, so the plotting utilities in
`rfmix_reader._visualization` work identically for RFMix, FLARE, and
Haptools-simulated inputs. The snippet below shows the typical workflow
for each reader:

```python
from rfmix_reader import (
    plot_ancestry_by_chromosome,
    plot_global_ancestry,
    read_flare,
    read_rfmix,
    read_simu,
)

# RFMix run directory
loci_df, g_anc, admix = read_rfmix("two_pops/out/")
plot_global_ancestry(g_anc, save_path="rfmix_global.png")
plot_ancestry_by_chromosome(loci_df, admix, save_path="rfmix_local.png")

# FLARE output directory (contains *.anc.vcf.gz + global.anc.gz)
loci_df, g_anc, admix = read_flare("flare_runs/chr1/")
plot_global_ancestry(g_anc, save_path="flare_global.png")
plot_ancestry_by_chromosome(loci_df, admix, save_path="flare_local.png")

# Haptools simulations (after reheadering contigs)
loci_df, g_anc, admix = read_simu("/path/to/simulations/")
plot_global_ancestry(g_anc, save_path="simu_global.png")
plot_ancestry_by_chromosome(loci_df, admix, save_path="simu_local.png")
```

`plot_global_ancestry` builds per-individual stacked bars of global
ancestry while `plot_ancestry_by_chromosome` summarizes local ancestry
along each chromosome, giving you quick visual QC for every supported
input format.

---

## Development Install

For contributors:

```bash
git clone https://github.com/heart-gen/rfmix_reader.git
cd rfmix_reader
pip install -e ".[gpu,docs,tests]"
```

---

## Citation

If you use this software, please cite:

[![DOI](https://zenodo.org/badge/807052842.svg)](https://zenodo.org/doi/10.5281/zenodo.12629787)

Benjamin, K. J. M. (2024). **RFMix-reader (Version 0.2.0)** \[Computer software].
[https://github.com/heart-gen/rfmix\_reader](https://github.com/heart-gen/rfmix_reader)

Kynon JM Benjamin. *"RFMix-reader: Accelerated reading and processing for local ancestry studies."*
**bioRxiv** (2024).
DOI: [10.1101/2024.07.13.603370](https://www.biorxiv.org/content/10.1101/2024.07.13.603370v2).

---

## Funding

This work was supported by the National Institutes of Health,
National Institute on Minority Health and Health Disparities (NIMHD)
K99MD016964 / R00MD016964.

