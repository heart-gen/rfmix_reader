#+TITLE:     Usage
#+AUTHOR:    Kynon J. Benjamin, Ph.D
#+EMAIL:     kynonjade.benjamin@libd.org
#+LANGUAGE:  en
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://gongzhitaao.org/orgcss/org.css"/>
#+PROPERTY:  header-args: :dir /dcs04/lieber/statsgen/jbenjami/tutorials/eqtl_analysis_tutorial
#+PROPERTY:  header-args:R :cache yes :exports both :session *R* :eval never-export
#+PROPERTY:  header-args:python :session *Python* :cache yes :exports both :eval never-export
#+PROPERTY:  header-args:sh :cache yes :exports both :eval never-export
#+OPTIONS:   H:3 num:nil toc:3 \n:nil @:t ::t |:t ^:{} -:t f:t *:t TeX:t LaTeX:t skip:t d:(HIDE) tags:not-in-toc
#+STARTUP:   align fold nodlcheck hidestars oddeven lognotestate
#+TAGS:      Write(w) Update(u) Fix(f) Check(c) noexport(n)

* General workflow
Using =rfmix-reader= is as simple as [[https://pandas-plink.readthedocs.io/en/latest/usage.html][=pandas-plink=]] but extended to
RFMix, FLARE, and Haptools simulations. The sections below show how to
prepare input data, read each supported format, understand the returned
objects, and visualize the results.

** Preparing input data
The canonical pipeline starts with RFMix's =*.fb.tsv= files. Convert them
to binary chunks with =create_binaries= to minimize later I/O.

#+begin_src python :results output
  from rfmix_reader import create_binaries

  prefix_path = "../examples/two_populations/out/"
  create_binaries(prefix_path)
#+end_src

#+RESULTS[20f284c23771c5bf268a8cb4a468752edf5b0410]:
: Created binary files at: ./binary_files
: Converting fb files to binary!
100% 3/3 [05:03<00:00, 101.27s/it]
As of =v0.1.20= you can also trigger the conversion from the CLI.
** Reading RFMix output
=read_rfmix= combines the loci metadata, chromosome-level global ancestry
files, and local ancestry chunks. If =binary_dir= is omitted the function
will transparently build the binaries in the background.
  from rfmix_reader import read_rfmix

  loci_df, g_anc, admix = read_rfmix(
      "../examples/two_populations/out/",
      binary_dir="../examples/two_populations/out/binary_files",
  )

To phase-correct local ancestry before stacking across chromosomes, pass
=phase=True= with the required reference inputs:

#+begin_src python :results output
  loci_df, g_anc, admix = read_rfmix(
      "../examples/two_populations/out/",
      phase=True,
      phase_vcf_path="/path/to/reference.vcf.gz",
      phase_sample_annot_path="/path/to/sample_annot.tsv",
  )
#+end_src

** Reading FLARE output
=read_flare= mirrors the =read_rfmix= interface but expects FLARE's
=*.anc.vcf.gz= and =global.anc.gz= pairs. The resulting =(loci_df, g_anc,
admix)= tuple therefore drops directly into the rest of the workflow.

#+begin_src python :results output
  from rfmix_reader import read_flare

  loci_df, g_anc, admix = read_flare("/path/to/flare/prefix/")
#+end_src

** Reading Haptools simulations
=read_simu= parses BGZF-compressed VCFs produced by
=haptools simgenotype --pop_field=. It infers the chromosome list,
computes the per-sample global ancestry matrix, and builds the same
output tuple as the other loaders.

#+begin_src python :results output
  from rfmix_reader import read_simu
  loci_df, g_anc, admix = read_simu("/path/to/simulations/")
#+end_src
* Understanding the outputs
Every reader returns =loci_df=, =g_anc=, and =admix= to keep downstream
code identical.
** =loci_df=
  loci_df.shape
  loci_df.head()
       chromosome  physical_position  i
0           chr20              60137  0
1           chr20              60291  1
2           chr20              60340  2
3           chr20              60440  3
4           chr20              60823  4

The =i= column mirrors =pandas_plink= and simplifies joins with other
variant-level resources.
** =g_anc=
=g_anc= (previously called =rf_q=) stores the global ancestry proportions
per individual and chromosome.
  g_anc.shape
  g_anc.head()
You can still extract sample IDs or the set of populations for later use.
  sample_ids = g_anc.sample_id.unique().to_arrow()
  pops = g_anc.drop(["sample_id", "chrom"], axis=1).columns.values
** =admix=
=admix= exposes the local ancestry array as a =dask.array=, matching the
BED semantics from =pandas_plink= so that only the requested chunks are
materialized into memory.
#+begin_src python :results value verbatim
#+RESULTS:
#+begin_src python :results value
#+RESULTS:
#+begin_example
[[2 2 2 ... 0 0 0]
 [2 2 1 ... 0 0 1]
 [1 2 1 ... 0 0 0]
 ...
 [1 1 2 ... 0 0 0]
 [2 2 2 ... 1 1 1]
 [2 2 1 ... 1 0 1]]
#+end_example
Column ordering follows the population-major convention (all individuals
for population 1, then all individuals for population 2, etc.). Generate
column labels with a list comprehension when needed.
#+RESULTS:
* Loci imputation
Imputing local ancestry loci information to genotype variant locations
improves downstream integration. The =interpolate_array= helper combines
RFMix loci with genotype coordinates using memory-efficient
[[https://zarr.readthedocs.io/en/stable/index.html][Zarr]] arrays.
#+begin_src python :results none

#+end_src
#+begin_src python :results none
                       "physical_position": "pos"},
              inplace=True)
  variant_df = variant_df.drop_duplicates(subset=["chrom", "pos"], keep='first')
                                     how="outer", indicator=True) \
                              .loc[:, ["chrom", "pos", "i", "_merge"]]
#+end_src

* Visualization
=rfmix-reader= bundles several plotting/export helpers so you can inspect
results without additional reshaping.

** Global summaries
Use =plot_global_ancestry= for per-individual stacked bars and
=plot_ancestry_by_chromosome= for chromosome-level boxplots. Both accept
the =save_path= and =save_multi_format= options exposed by the plotting
utilities.

#+begin_src python :results none
  from rfmix_reader import (
      plot_global_ancestry,
      plot_ancestry_by_chromosome,
  )

  plot_global_ancestry(g_anc, dpi=300, bbox_inches="tight")
  plot_ancestry_by_chromosome(g_anc, dpi=300, bbox_inches="tight")
#+end_src

** Export for TAGORE and BED-based tools
=generate_tagore_bed= converts =(loci_df, g_anc, admix)= to an annotated
BED-style table that matches TAGORE's expectations. Use it whenever you
need external visualization or browser-ready tracks.

#+begin_src python :results value
  from rfmix_reader import generate_tagore_bed

  tagore_df = generate_tagore_bed(loci_df, g_anc, admix, sample_num=0)
  tagore_df.head()
#+end_src
#+end_src

#+RESULTS[943d0f4206518c373fa852ab000059693e2b2897]:
: ['AFR' 'EUR']

*** =admix=
=admix= is the convert RFMix results from the =*.fb.tsv= files.
Here, we add the alleles and re-subset the data so that the
first population is first (all samples) followed by the next, and
the next. This means instead of 0 and 1, you can get 0, 1, or 3.

#+begin_src python :results value
  admix
#+end_src

#+RESULTS[786d091553720e67cc5780ad7bbd2265492be434]:
: dask.array<concatenate, shape=(646287, 1000), dtype=float32, chunksize=(1024, 256), chunktype=numpy.ndarray>

To reduce memory consumption, this large data is held in a
dask array, exactly like =pandas_plink= BED data.

#+begin_src python :results value verbatim
  admix.compute()
#+end_src

#+RESULTS[070fc2065a660e8042230bf7713804fdb124fbba]:
: [[2 2 2 ... 0 0 0]
:  [2 2 1 ... 0 0 1]
:  [1 2 1 ... 0 0 0]
:  ...
:  [1 1 2 ... 0 0 0]
:  [2 2 2 ... 1 1 1]
:  [2 2 1 ... 1 0 1]]

#+begin_src python :results value verbatim
  admix.shape
#+end_src

#+RESULTS[19574afcca5d5cbc89e58eb226076e4ed3afeab7]:
: (646287, 1000)

The rows are the same as the =loci= data, in the sample order.

#+begin_src python :results value verbatim
  loci.shape
#+end_src

#+RESULTS[217b70fa31fcce528d45f44213a25d1722e1309b]:
: (646287, 3)

The rows are the total samples x number of populations. This
is in a specific order. All samples are grouped by population
instead of by the sample.

#+begin_src python :results value verbatim
  col_names = [f"{sample}_{pop}" for pop in pops for sample in sample_ids]
  len(col_names)
#+end_src

#+RESULTS[6d3b0a823d116490484f2500f47ebbb03fcd208c]:
: 1000

#+begin_src python :results value verbatim
  col_names[0:4]
#+end_src

#+RESULTS[c8ca5d8c680865988858e9cafb571adceb27970d]:
: ['Sample_1_AFR', 'Sample_2_AFR', 'Sample_3_AFR', 'Sample_4_AFR']

#+begin_src python :results value verbatim
  col_names[500:504]
#+end_src

#+RESULTS[9889ae17959e0911178a53e41e70d58d7ce11224]:
: ['Sample_1_EUR', 'Sample_2_EUR', 'Sample_3_EUR', 'Sample_4_EUR']

This is the correct order for the admix array data.

* Loci Imputation
Imputing local ancestry loci information to genotype variant locations improves
integration of the local ancestry information with genotype data. As such, we also
provide the =interpolate_array= function to efficiently interpolate missing values
when local ancestry loci information is converted to more variable genotype variant
locations. It leverages the power of [[https://zarr.readthedocs.io/en/stable/index.html][=Zarr=]] arrays, making it suitable for handling
substantial datasets while managing memory usage effectively.

*Note*: Following imputation, =variant_df= will include genomic positions for
both local ancestry and genotype data.

#+BEGIN_SRC python :results silent
  def _load_genotypes(plink_prefix_path):
      from tensorqtl import pgen
      pgr = pgen.PgenReader(plink_prefix_path)
      variant_df = pgr.variant_df
      variant_df.loc[:, "chrom"] = "chr" + variant_df.chrom
      return pgr.load_genotypes(), variant_df

  def _load_admix(prefix_path, binary_dir):
      from rfmix_reader import read_rfmix
      return read_rfmix(prefix_path, binary_dir=binary_dir)

#+END_SRC

#+BEGIN_SRC python :results silent
  from rfmix_reader import interpolate_array
  basename = "/projects/b1213/large_projects/brain_coloc_app/input"
  # Local ancestry
  prefix_path = f"{basename}/local_ancestry_rfmix/_m/"
  binary_dir = f"{basename}/local_ancestry_rfmix/_m/binary_files/"
  loci, _, admix = _load_admix(prefix_path, binary_dir)
  loci.rename(columns={"chromosome": "chrom",
		       "physical_position": "pos"},
	      inplace=True)
  # Variant data
  plink_prefix = f"{basename}/genotypes/TOPMed_LIBD"
  _, variant_df = _load_genotypes(plink_prefix)
  variant_df = variant_df.drop_duplicates(subset=["chrom", "pos"],
					  keep='first')
  # Keep all locations for more accurate imputation
  variant_loci_df = variant_df.merge(loci.to_pandas(), on=["chrom", "pos"],
				     how="outer", indicator=True)\
			      .loc[:, ["chrom", "pos", "i", "_merge"]]
  data_path = f"{basename}/local_ancestry_rfmix/_m"
  z = interpolate_array(variant_loci_df, admix, data_path)
#+END_SRC
